{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any, Optional\n",
    "import logging\n",
    "import json\n",
    "import pprint\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from autogen import ConversableAgent\n",
    "from autogen import GroupChat\n",
    "from autogen import GroupChatManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_openai_api_key\n",
    "\n",
    "OPENAI_API_KEY = get_openai_api_key()\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"llama3\",\n",
    "        \"base_url\": \"http://localhost:11434/v1\",\n",
    "        'api_key': 'ollama',\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duckduckgo_search(search_term: str, max_results: int = 5) -> Optional[List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Perform a DuckDuckGo search and return the search results as a list.\n",
    "\n",
    "    Args:\n",
    "        search_term (str): The term to use for the search.\n",
    "        max_results (int): The maximum number of results to return. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        Optional[List[Dict[str, Any]]]: A list of search results, or None if the search term is empty.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = DDGS().text(search_term, max_results=max_results)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error searching DuckDuckGo: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'GitHub - microsoft/autogen: A programming framework for agentic AI ...',\n",
       "  'href': 'https://github.com/microsoft/autogen',\n",
       "  'body': 'AutoGen v0.4 is a rewrite of AutoGen from the ground up to create a more robust, scalable, easier to use, cross-language library for building AI Agents. Some key features include asynchronous messaging, support for scalable distributed agents, modular extensible design (bring your own agents, implement behaviors however you like), cross ...'},\n",
       " {'title': 'AutoGen | AutoGen - GitHub Pages',\n",
       "  'href': 'https://microsoft.github.io/autogen/0.2/',\n",
       "  'body': 'AutoGen provides multi-agent conversation framework as a high-level abstraction. With this framework, one can conveniently build LLM workflows. Easily Build Diverse Applications. AutoGen offers a collection of working systems spanning a wide range of applications from various domains and complexities.'},\n",
       " {'title': 'AutoGen: Enabling next-generation large language model applications',\n",
       "  'href': 'https://www.microsoft.com/en-us/research/blog/autogen-enabling-next-generation-large-language-model-applications/',\n",
       "  'body': 'AutoGen is a Microsoft Research project that simplifies the orchestration, optimization, and automation of large language model (LLM) workflows. It enables customizable and conversable agents that can integrate with humans, tools, and other LLMs to solve complex tasks via chat.'},\n",
       " {'title': 'Getting Started | AutoGen - GitHub Pages',\n",
       "  'href': 'https://microsoft.github.io/autogen/0.2/docs/Getting-Started/',\n",
       "  'body': 'AutoGen is an open-source programming framework for building AI agents and facilitating cooperation among multiple agents to solve tasks. AutoGen aims to provide an easy-to-use and flexible framework for accelerating development and research on agentic AI, like PyTorch for Deep Learning.'},\n",
       " {'title': 'AutoGen - Microsoft Research',\n",
       "  'href': 'https://www.microsoft.com/en-us/research/project/autogen/',\n",
       "  'body': 'AutoGen provides a multi-agent conversation framework as a high-level abstraction. It is an open-source library for enabling next-generation LLM applications with multi-agent collaborations, teachability and personalization. With this framework, users can build LLM workflows. The agent modularity and conversation-based programming simplifies ...'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test duckduckgo_search function\n",
    "search_term = \"Autogen\"\n",
    "duckduckgo_search(search_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_url(url: str, timeout: int = 10) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Scrape the content of a given URL and return it as a string.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL to scrape.\n",
    "        timeout (int): The timeout in seconds for the request. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The scraped content as a string, or None if the request fails.\n",
    "    \"\"\"\n",
    "    # Set up Selenium options to run headless\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--window-size=1920x1080\")\n",
    "    options.add_argument(\"--log-level=3\")\n",
    "\n",
    "    # Set up the webdriver\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "    try:\n",
    "        # Open the URL\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the page to load\n",
    "        WebDriverWait(driver, timeout).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "        )\n",
    "\n",
    "        # Get the page source\n",
    "        page_source = driver.page_source\n",
    "\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "        # Extract the text content\n",
    "        text_content = soup.get_text(separator=' ', strip=True)\n",
    "\n",
    "        return text_content\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error ocured while scraping {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "    finally:\n",
    "        # Close the webdriver\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GitHub - microsoft/autogen: A programming framework for agentic AI ðŸ¤– (PyPi: autogen-agentchat) Skip to content Navigation Menu Toggle navigation Sign in Product GitHub Copilot Write better code with AI Security Find and fix vulnerabilities Actions Automate any workflow Codespaces Instant dev environments Issues Plan and track work Code Review Manage code changes Discussions Collaborate outside of code Code Search Find more, search less Explore All features Documentation GitHub Skills Blog Solutions By company size Enterprises Small and medium teams Startups By use case DevSecOps DevOps CI/CD View all use cases By industry Healthcare Financial services Manufacturing Government View all industries View all solutions Resources Topics AI DevOps Security Software Development View all Explore Learning Pathways White papers, Ebooks, Webinars Customer Stories Partners Executive Insights Open Source GitHub Sponsors Fund open source developers The ReadME Project GitHub community articles Repositories Topics Trending Collections Enterprise Enterprise platform AI-powered developer platform Available add-ons Advanced Security Enterprise-grade security features GitHub Copilot Enterprise-grade AI features Premium Support Enterprise-grade 24/7 support Pricing Search or jump to... Search code, repositories, users, issues, pull requests... Search Clear Search syntax tips Provide feedback We read every piece of feedback, and take your input very seriously. Include my email address so I can be contacted Cancel Submit feedback Saved searches Use saved searches to filter your results more quickly Name Query To see all available qualifiers, see our documentation . Cancel Create saved search Sign in Sign up Reseting focus You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert microsoft / autogen Public Notifications You must be signed in to change notification settings Fork 5.2k Star 35.8k A programming framework for agentic AI ðŸ¤– (PyPi: autogen-agentchat) microsoft.github.io/autogen/0.4.0.dev11/ License CC-BY-4.0, MIT licenses found Licenses found CC-BY-4.0 LICENSE MIT LICENSE-CODE 35.8k stars 5.2k forks Branches Tags Activity Star Notifications You must be signed in to change notification settings Code Issues 588 Pull requests 38 Discussions Actions Projects 0 Security Insights Additional navigation options Code Issues Pull requests Discussions Actions Projects Security Insights microsoft/autogen main Branches Tags Go to file Code Folders and files Name Name Last commit message Last commit date Latest commit History 2,886 Commits .azure/ pipelines .azure/ pipelines .devcontainer .devcontainer .github .github docs docs dotnet dotnet protos protos python python .gitattributes .gitattributes .gitignore .gitignore CODE_OF_CONDUCT.md CODE_OF_CONDUCT.md CONTRIBUTING.md CONTRIBUTING.md LICENSE LICENSE LICENSE-CODE LICENSE-CODE README.md README.md SECURITY.md SECURITY.md SUPPORT.md SUPPORT.md TRANSPARENCY_FAQS.md TRANSPARENCY_FAQS.md View all files Repository files navigation README Code of conduct More Repository files items CC-BY-4.0 license MIT license Security AutoGen Important (12/11/24) We have created a new Discord server for the AutoGen community. Join us at aka.ms/autogen-discord . (11/14/24) âš ï¸ In response to a number of asks to clarify and distinguish between official AutoGen and its forks that created confusion, we issued a clarification statement . (10/13/24) Interested in the standard AutoGen as a prior user? Find it at the actively-maintained AutoGen 0.2 branch and autogen-agentchat~=0.2 PyPi package. (10/02/24) AutoGen 0.4 is a from-the-ground-up rewrite of AutoGen. Learn more about the history, goals and future at this blog post . Weâ€™re excited to work with the community to gather feedback, refine, and improve the project before we officially release 0.4. This is a big change, so AutoGen 0.2 is still available, maintained, and developed in the 0.2 branch . Join us for Community Office Hours We will host a weekly open discussion to answer questions, talk about Roadmap, etc. AutoGen is an open-source framework for building AI agent systems.\\nIt simplifies the creation of event-driven, distributed, scalable, and resilient agentic applications.\\nIt allows you to quickly build systems where AI agents collaborate and perform tasks autonomously\\nor with human oversight. Key Features API Layering Quickstart Roadmap FAQs AutoGen streamlines AI development and research, enabling the use of multiple large language models (LLMs), integrated tools, and advanced multi-agent design patterns. You can develop and test your agent systems locally, then deploy to a distributed cloud environment as your needs grow. Key Features AutoGen offers the following key features: Asynchronous Messaging : Agents communicate via asynchronous messages, supporting both event-driven and request/response interaction patterns. Full type support : use types in all interfaces and enforced type check on build, with a focus on quality and cohesiveness Scalable & Distributed : Design complex, distributed agent networks that can operate across organizational boundaries. Modular & Extensible : Customize your system with pluggable components: custom agents, tools, memory, and models. Cross-Language Support : Interoperate agents across different programming languages. Currently supports Python and .NET, with more languages coming soon. Observability & Debugging : Built-in features and tools for tracking, tracing, and debugging agent interactions and workflows, including support for industry standard observability with OpenTelemetry â†‘ Back to Top â†‘ API Layering AutoGen has several packages and is built upon a layered architecture.\\nCurrently, there are three main APIs your application can target: Core AgentChat Extensions Core Installation Quickstart The core API of AutoGen, autogen-core , is built following the actor model .\\nIt supports asynchronous message passing between agents and event-based workflows.\\nAgents in the core layer handle and produce typed messages, using either direct messaging,\\nwhich functions like RPC, or via broadcasting to topics, which is pub-sub.\\nAgents can be distributed and implemented in different programming languages,\\nwhile still communicating with one another. Start here if you are building scalable, event-driven agentic systems. AgentChat Installation Quickstart The AgentChat API, autogen-agentchat , is task driven and at a high level like AutoGen 0.2.\\nIt allows you to define conversational agents, compose them into teams and then\\nuse them to solve tasks.\\nAgentChat itself is built on the core layer, but it abstracts away much of its\\nlow-level system concepts.\\nIf your workflows don\\'t fit into the AgentChat API, target core instead. Start here if you just want to focus on quickly getting started with multi-agents workflows. Extensions The extension package autogen-ext contains implementations of the core interfaces using 3rd party systems,\\nsuch as OpenAI model client and Azure code executors.\\nBesides the built-in extensions, the package accommodates community-contributed\\nextensions through namespace sub-packages.\\nWe look forward to your contributions! â†‘ Back to Top â†‘ Quickstart Python (AgentChat) First install the packages: pip install \\' autogen-agentchat==0.4.0.dev11 \\' \\' autogen-ext[openai]==0.4.0.dev11 \\' The following code uses OpenAI\\'s GPT-4o model and you need to provide your\\nAPI key to run.\\nTo use Azure OpenAI models, follow the instruction here . import asyncio from autogen_agentchat . agents import AssistantAgent from autogen_agentchat . ui import Console from autogen_agentchat . conditions import TextMentionTermination from autogen_agentchat . teams import RoundRobinGroupChat from autogen_ext . models . openai import OpenAIChatCompletionClient # Define a tool async def get_weather ( city : str ) -> str : return f\"The weather in { city } is 73 degrees and Sunny.\" async def main () -> None : # Define an agent weather_agent = AssistantAgent ( name = \"weather_agent\" , model_client = OpenAIChatCompletionClient ( model = \"gpt-4o-2024-08-06\" , # api_key=\"YOUR_API_KEY\", ), tools = [ get_weather ],\\n    ) # Define termination condition termination = TextMentionTermination ( \"TERMINATE\" ) # Define a team agent_team = RoundRobinGroupChat ([ weather_agent ], termination_condition = termination ) # Run the team and stream messages to the console stream = agent_team . run_stream ( task = \"What is the weather in New York?\" ) await Console ( stream ) asyncio . run ( main ()) C# The .NET SDK does not yet support all of the interfaces that the python SDK offers but we are working on bringing them to parity.\\nTo use the .NET SDK, you need to add a package reference to the src in your project.\\nWe will release nuget packages soon and will update these instructions when that happens. git clone https://github.com/microsoft/autogen.git\\ncd autogen\\n# Switch to the branch that has this code\\ngit switch staging-dev\\n# Build the project\\ncd dotnet && dotnet build AutoGen.sln\\n# In your source code, add AutoGen to your project\\ndotnet add <your.csproj> reference <path to your checkout of autogen>/dotnet/src/Microsoft.AutoGen/Core/Microsoft.AutoGen.Core.csproj Then, define and run your first agent: using Microsoft . AutoGen . Contracts ; using Microsoft . AutoGen . Core ; using Microsoft . Extensions . DependencyInjection ; using Microsoft . Extensions . Hosting ; // send a message to the agent var app = await App . PublishMessageAsync ( \"HelloAgents\" , new NewMessageReceived { Message = \"World\" } , local : true ) ; await App . RuntimeApp ! . WaitForShutdownAsync ( ) ; await app . WaitForShutdownAsync ( ) ; [ TopicSubscription ( \"agents\" ) ] public class HelloAgent ( IAgentContext context , [ FromKeyedServices ( \"EventTypes\" ) ] EventTypes typeRegistry ) : ConsoleAgent ( context , typeRegistry ) , ISayHello , IHandle < NewMessageReceived > , IHandle < ConversationClosed > { public async Task Handle ( NewMessageReceived item ) { var response = await SayHello ( item . Message ) . ConfigureAwait ( false ) ; var evt = new Output { Message = response } . ToCloudEvent ( this . AgentId . Key ) ; await PublishEventAsync ( evt ) . ConfigureAwait ( false ) ; var goodbye = new ConversationClosed { UserId = this . AgentId . Key , UserMessage = \"Goodbye\" } . ToCloudEvent ( this . AgentId . Key ) ; await PublishEventAsync ( goodbye ) . ConfigureAwait ( false ) ; } public async Task Handle ( ConversationClosed item ) { var goodbye = $ \"********************* { item . UserId } said { item . UserMessage } ************************\" ; var evt = new Output { Message = goodbye } . ToCloudEvent ( this . AgentId . Key ) ; await PublishEventAsync ( evt ) . ConfigureAwait ( false ) ; await Task . Delay ( 60000 ) ; await App . ShutdownAsync ( ) ; } public async Task < string > SayHello ( string ask ) { var response = $ \" \\\\n \\\\n \\\\n \\\\n ***************Hello { ask } ********************** \\\\n \\\\n \\\\n \\\\n \" ; return response ; } } public interface ISayHello { public Task < string > SayHello ( string ask ) ; } dotnet run â†‘ Back to Top â†‘ Roadmap AutoGen 0.2 - This is the current stable release of AutoGen. We will continue to accept bug fixes and minor enhancements to this version. AutoGen 0.4 - This is the first release of the new architecture. This release is still in preview . We will be focusing on the stability of the interfaces, documentation, tutorials, samples, and a collection of built-in agents which you can use. We are excited to work with our community to define the future of AutoGen. We are looking for feedback and contributions to help shape the future of this project. Here are some major planned items: More programming languages (e.g., TypeScript) More built-in agents and multi-agent workflows Deployment of distributed agents Re-implementation/migration of AutoGen Studio Integration with other agent frameworks and data sources Advanced RAG techniques and memory services â†‘ Back to Top â†‘ FAQs What is AutoGen 0.4? AutoGen v0.4 is a rewrite of AutoGen from the ground up to create a more robust,\\nscalable, easier to use, cross-language library for building AI Agents.\\nSome key features include asynchronous messaging, support for scalable distributed agents,\\nmodular extensible design (bring your own agents, implement behaviors however you like),\\ncross-language support, improved observability, and full typing integration.\\nIt is a breaking change. Why these changes? We listened to our AutoGen users, learned from what was working, and adapted to fix what wasn\\'t.\\nWe brought together wide-ranging teams working on many different types of AI Agents\\nand collaborated to design an improved framework with a more flexible\\nprogramming model and better scalability. Is this project still maintained? We want to reaffirm our commitment to supporting both the original version of AutoGen (0.2) and the redesign (0.4) . AutoGen 0.4 is still work-in-progress, and we shared the code now to build with the community. There are no plans to deprecate the original AutoGen anytime soon, and both versions will be actively maintained. Who should use it 0.4? This code is still experimental, so expect changes and bugs while we work towards a stable 0.4 release. We encourage early adopters to\\ntry it out, give us feedback, and contribute.\\nFor those looking for a stable version we recommend to continue using 0.2 I\\'m using AutoGen 0.2, should I upgrade? If you consider yourself an early adopter, you are comfortable making some\\nchanges to your code, and are willing to try it out, then yes. How do I still use AutoGen 0.2? AutoGen 0.2 can be installed with: pip install autogen-agentchat~=0.2 Will AutoGen Studio be supported in 0.4? Yes, this is on the roadmap .\\nOur current plan is to enable an implementation of AutoGen Studio\\non the AgentChat high level API which implements a set of agent functionalities\\n(agents, teams, etc). How do I migrate? For users familiar with AutoGen, the AgentChat library in 0.4 provides similar concepts.\\nWe are working on a migration guide. Is 0.4 done? We are still actively developing AutoGen 0.4. One exciting new feature is the emergence of new SDKs for .NET. The python SDKs are further ahead at this time but our goal is to achieve parity. We aim to add additional languages in future releases. What is happening next? When will this release be ready? We are still working on improving the documentation, samples, and enhancing the code. We are hoping to release before the end of the year when things are ready. What is the history of this project? The rearchitecture of the framework started with multiple Microsoft teams coming together\\nto address the gaps and learnings from AutoGen 0.2 - merging ideas from several predecessor projects.\\nThe team worked on this internally for some time to ensure alignment before moving work back to the open in October 2024. What is the official channel for support? Use GitHub Issues for bug reports and feature requests.\\nUse GitHub Discussions for general questions and discussions. Do you use Discord for communications? We are unable to use the old Discord for project discussions, many of the maintainers no longer have viewing or posting rights there. Therefore, we request that all discussions take place on https://github.com/microsoft/autogen/discussions/ or the new discord server . What about forks? https://github.com/microsoft/autogen/ remains the only official repo for development and support of AutoGen.\\nWe are aware that there are thousands of forks of AutoGen, including many for personal development and startups building with or on top of the library. We are not involved with any of these forks and are not aware of any plans related to them. What is the status of the license and open source? Our project remains fully open-source and accessible to everyone. We understand that some forks use different licenses to align with different interests. We will continue to use the most permissive license (MIT) for the project. Can you clarify the current state of the packages? Currently, we are unable to make releases to the pyautogen package via Pypi due to a change to package ownership that was done without our involvement. Additionally, we are moving to using multiple packages to align with the new design. Please see details here . Can I still be involved? We are grateful to all the contributors to AutoGen 0.2 and we look forward to continuing to collaborate with everyone in the AutoGen community. â†‘ Back to Top â†‘ Legal Notices Microsoft and any contributors grant you a license to the Microsoft documentation and other content\\nin this repository under the Creative Commons Attribution 4.0 International Public License ,\\nsee the LICENSE file, and grant you a license to any code in the repository under the MIT License , see the LICENSE-CODE file. Microsoft, Windows, Microsoft Azure, and/or other Microsoft products and services referenced in the documentation\\nmay be either trademarks or registered trademarks of Microsoft in the United States and/or other countries.\\nThe licenses for this project do not grant you rights to use any Microsoft names, logos, or trademarks.\\nMicrosoft\\'s general trademark guidelines can be found at http://go.microsoft.com/fwlink/?LinkID=254653 . Privacy information can be found at https://go.microsoft.com/fwlink/?LinkId=521839 Microsoft and any contributors reserve all other rights, whether under their respective copyrights, patents,\\nor trademarks, whether by implication, estoppel, or otherwise. â†‘ Back to Top â†‘ About A programming framework for agentic AI ðŸ¤– (PyPi: autogen-agentchat) microsoft.github.io/autogen/0.4.0.dev11/ Topics chat chatbot gpt chat-application agent-based-framework agent-oriented-programming gpt-4 chatgpt llmops gpt-35-turbo llm-agent llm-inference agentic llm-framework agentic-agi Resources Readme License CC-BY-4.0, MIT licenses found Licenses found CC-BY-4.0 LICENSE MIT LICENSE-CODE Code of conduct Code of conduct Security policy Security policy Activity Custom properties Stars 35.8k stars Watchers 414 watching Forks 5.2k forks Report repository Releases 63 v0.2.39 Latest Nov 25, 2024 + 62 releases Packages 0 Used by 2.4k + 2,398 Contributors 410 + 396 contributors Languages Python 28.8% Jupyter Notebook 28.7% C# 22.4% HTML 14.4% TypeScript 4.9% JavaScript 0.5% Other 0.3% Footer Â© 2024 GitHub,\\xa0Inc. Footer navigation Terms Privacy Security Status Docs Contact Manage cookies Do not share my personal information You canâ€™t perform that action at this time.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test scrape_url function\n",
    "url = \"https://github.com/microsoft/autogen\"\n",
    "scrape_url(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent - DuckDuckGo Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_ddgo = ConversableAgent(\n",
    "    name=\"AI_Assistant_in_DuckDuckGo_Search\",\n",
    "    system_message=\"You are a helpful AI assistant. You can only help using search tool. \"\n",
    "    \"You list them in bullet points, in a format <title>, <href> .\"\n",
    "    \"Return '$$$TERMINATE$$$' when the task is done.\",\n",
    "    llm_config={\n",
    "        \"config_list\": config_list,\n",
    "        \"temperature\": 0.7,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent - Scrape & Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_scrape_summarize = ConversableAgent(\n",
    "    name=\"AI_Assistant_Scraping_Summarizing\",\n",
    "    system_message=\"You will first scrape a given hyperlink for content, and then you will wrie a summary. \"\n",
    "    \"If you are given a specific instruction or requirement for a summary (such as be concise or write in two paragraphs), you must follow the instruction. \"\n",
    "    \"Otherwise, you will write a summary in between 3 to 5 bullet points. \"\n",
    "    \"Sometimes, scraping will fall possibly with many reason, including dead links or being blocked from scraping. \"\n",
    "    \"If that happenes, you must say 'information scraping failed'.\"\n",
    "    \"Return '$$$TERMINATE$$$' when the task is done.\",\n",
    "    llm_config={\n",
    "        \"config_list\": config_list,\n",
    "        \"temperature\": 0.7,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent - Lead Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_summarize_lead = ConversableAgent(\n",
    "    name=\"Lead_Scrape_Summarize\",\n",
    "    system_message=\"You will get a list of one or more websites from another AI that uses search engine tools. \"\n",
    "    \"You will orchestrate summarization. You will work with another AI who scrapes a link and summarizes its content. \"\n",
    "    \"You will order that AI to do its task ONE LINK AT A TIME, and you instruct that AI to output a short summary paragraph. \"\n",
    "    \"When all websites in the list are summarized, you yourself will combine them into one final summarization answer. \"\n",
    "    \"Your summary will be in pullet points, from 5 to 10 points. \"\n",
    "    \"Return '$$$TERMINATE$$$' when the WHOLE task is done OR no link left to perform the task.\"\n",
    "    \"DO NOT ask for more links to process.\",\n",
    "    llm_config={\n",
    "        \"config_list\": config_list,\n",
    "        \"temperature\": 0.7,\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
